{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os.path\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'D:/Jupyter Projects/data/Marmoset/Oddball/withafterICA'\n",
    "# freq_list = [700,800,900,1000,1100,1200,1300,1400,1500,1600]\n",
    "data_file = dataset_dir + \"/sound_data_odd.pkl\"\n",
    "with open(data_file, 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "whole_train_data = []\n",
    "label_train_data = []\n",
    "whole_test_data = []\n",
    "label_test_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_num = 2\n",
    "\n",
    "n_datapoint = 125\n",
    "n_channel = 96 #ecog.shape[0]\n",
    "# n_epoch = 100 #int(ecog.shape[1] / n_datapoint);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 900, 125)\n",
      "(900, 12000)\n"
     ]
    }
   ],
   "source": [
    "# odd 1\n",
    "\n",
    "n_epoch = 900\n",
    "print(dataset[1].shape)\n",
    "ecog = dataset[1].reshape(96,-1)\n",
    "ecog_data = ecog[0, :].reshape(n_epoch, n_datapoint)\n",
    "for ch in range (1, n_channel):\n",
    "    ecog_data = np.append(ecog_data, ecog[ch, :].reshape(n_epoch, n_datapoint), axis=1)\n",
    "\n",
    "print(ecog_data.shape)\n",
    "\n",
    "ecog_train_data = ecog_data[0:int(n_epoch*0.8)]\n",
    "ecog_test_data = ecog_data[int(n_epoch*0.8):int(n_epoch)]\n",
    "\n",
    "whole_train_data = ecog_train_data.astype(np.float32)\n",
    "whole_test_data = ecog_test_data.astype(np.float32)\n",
    "\n",
    "label_train_data = np.append(label_train_data, np.ones(int(n_epoch*0.8))*0)\n",
    "label_test_data = np.append(label_test_data, np.ones(int(n_epoch*0.2))*0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 100, 125)\n",
      "(100, 12000)\n"
     ]
    }
   ],
   "source": [
    "# odd 2\n",
    "\n",
    "n_epoch = 100\n",
    "print(dataset[2].shape)\n",
    "ecog = dataset[2].reshape(96,-1)\n",
    "ecog_data = ecog[0, :].reshape(n_epoch, n_datapoint)\n",
    "for ch in range (1, n_channel):\n",
    "    ecog_data = np.append(ecog_data, ecog[ch, :].reshape(n_epoch, n_datapoint), axis=1)\n",
    "\n",
    "print(ecog_data.shape)\n",
    "\n",
    "ecog_train_data = ecog_data[0:int(n_epoch*0.8)]\n",
    "ecog_test_data = ecog_data[int(n_epoch*0.8):int(n_epoch)]\n",
    "\n",
    "whole_train_data = np.append(whole_train_data, ecog_train_data.astype(np.float32), axis=0)\n",
    "whole_test_data = np.append(whole_test_data, ecog_test_data.astype(np.float32), axis=0)\n",
    "\n",
    "label_train_data = np.append(label_train_data, np.ones(int(n_epoch*0.8))*1)\n",
    "label_test_data = np.append(label_test_data, np.ones(int(n_epoch*0.2))*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(800, 96, 125)\n",
      "(800,)\n"
     ]
    }
   ],
   "source": [
    "whole_train_data = whole_train_data.reshape(800,96,125)\n",
    "whole_test_data = whole_test_data.reshape(200,96,125)\n",
    "print(type(whole_train_data))\n",
    "print(whole_train_data.shape)\n",
    "print(label_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "whole_train_data = torch.from_numpy(whole_train_data)\n",
    "# type(whole_train_data)\n",
    "label_train_data = torch.from_numpy(label_train_data)\n",
    "whole_test_data = torch.from_numpy(whole_test_data)\n",
    "label_test_data = torch.from_numpy(label_test_data)\n",
    "# whole_train_data = whole_train_data.astype(np.double)\n",
    "# whole_test_data = whole_test_data.astype(np.double)\n",
    "# label_train_data = label_train_data.astype(np.double)\n",
    "# label_test_data = label_test_data.astype(np.double)\n",
    "print(type(whole_train_data), type(whole_test_data), type(label_train_data), type(label_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_data = TensorDataset(whole_train_data, label_train_data)\n",
    "final_test_data = TensorDataset(whole_test_data, label_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Jupyter Projects/Mid-term/sound_dataset_odd.pkl\n",
      "Creating pickle file ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "save_file = \"D:/Jupyter Projects/Mid-term/sound_dataset_odd.pkl\"\n",
    "print(save_file)\n",
    "print(\"Creating pickle file ...\")\n",
    "with open(save_file, 'wb') as f:\n",
    "    pickle.dump([final_train_data,final_test_data], f, -1)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'D:/Jupyter Projects/Mid-term/sound_dataset_odd.pkl'\n",
    "with open(data_file, 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-dfc7bb704f63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dataset[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
