{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 100\n",
    "# NUM_CLASSES = 10\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'data/ecog_mel60_bi_dataset.pkl'\n",
    "with open(data_file, 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=dataset[0],\n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset[1],\n",
    "                                          batch_size=BATCH_SIZE, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BinarizedF(Function):\n",
    "#     def forward(self, input):\n",
    "#         self.save_for_backward(input)\n",
    "#         a = torch.ones_like(input)\n",
    "#         b = -torch.ones_like(input)\n",
    "#         output = torch.where(input>=0,a,b)\n",
    "#         return output\n",
    "#     def backward(self, output_grad):\n",
    "#         input, = self.saved_tensors\n",
    "#         input_abs = torch.abs(input)\n",
    "#         ones = torch.ones_like(input)\n",
    "#         zeros = torch.zeros_like(input)\n",
    "#         input_grad = torch.where(input_abs<=1,ones, zeros)\n",
    "#         return input_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 5, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(5, 10, kernel_size=3, padding=1)\n",
    "#         self.mp = nn.MaxPool2d(3)\n",
    "        self.gap = nn.AvgPool2d(1)\n",
    "        self.fc = nn.Linear(120000, 384)\n",
    "#         self.fc2 = nn.Linear(120000, 6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        in_size = x.size(0)\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x2 = F.relu(self.conv2(x1))\n",
    "        x3 = self.gap(x2)\n",
    "        x4 = x3.view(in_size, -1)\n",
    "        x5 = self.fc(x4)\n",
    "#         x5 = torch.squeeze(x5)\n",
    "#         return (x5>0.5).float().requires_grad_()\n",
    "        return x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(5, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (gap): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=120000, out_features=384, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.0693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hyde\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 11.9267\n",
      "\n",
      "Epoch [2/100], Loss: 0.0311\n",
      "\n",
      "Test set: Average loss: 12.0483\n",
      "\n",
      "Epoch [3/100], Loss: 0.0315\n",
      "\n",
      "Test set: Average loss: 12.0037\n",
      "\n",
      "Epoch [4/100], Loss: 0.0310\n",
      "\n",
      "Test set: Average loss: 11.8124\n",
      "\n",
      "Epoch [5/100], Loss: 0.0309\n",
      "\n",
      "Test set: Average loss: 11.7603\n",
      "\n",
      "Epoch [6/100], Loss: 0.0306\n",
      "\n",
      "Test set: Average loss: 11.4218\n",
      "\n",
      "Epoch [7/100], Loss: 0.0298\n",
      "\n",
      "Test set: Average loss: 11.3773\n",
      "\n",
      "Epoch [8/100], Loss: 0.0298\n",
      "\n",
      "Test set: Average loss: 11.1477\n",
      "\n",
      "Epoch [9/100], Loss: 0.0291\n",
      "\n",
      "Test set: Average loss: 11.0589\n",
      "\n",
      "Epoch [10/100], Loss: 0.0287\n",
      "\n",
      "Test set: Average loss: 10.8936\n",
      "\n",
      "Epoch [11/100], Loss: 0.0280\n",
      "\n",
      "Test set: Average loss: 10.8059\n",
      "\n",
      "Epoch [12/100], Loss: 0.0276\n",
      "\n",
      "Test set: Average loss: 10.4985\n",
      "\n",
      "Epoch [13/100], Loss: 0.0277\n",
      "\n",
      "Test set: Average loss: 10.4486\n",
      "\n",
      "Epoch [14/100], Loss: 0.0270\n",
      "\n",
      "Test set: Average loss: 10.3010\n",
      "\n",
      "Epoch [15/100], Loss: 0.0273\n",
      "\n",
      "Test set: Average loss: 10.1252\n",
      "\n",
      "Epoch [16/100], Loss: 0.0262\n",
      "\n",
      "Test set: Average loss: 10.0383\n",
      "\n",
      "Epoch [17/100], Loss: 0.0265\n",
      "\n",
      "Test set: Average loss: 9.8616\n",
      "\n",
      "Epoch [18/100], Loss: 0.0250\n",
      "\n",
      "Test set: Average loss: 9.7250\n",
      "\n",
      "Epoch [19/100], Loss: 0.0251\n",
      "\n",
      "Test set: Average loss: 9.5265\n",
      "\n",
      "Epoch [20/100], Loss: 0.0248\n",
      "\n",
      "Test set: Average loss: 9.3778\n",
      "\n",
      "Epoch [21/100], Loss: 0.0245\n",
      "\n",
      "Test set: Average loss: 9.2674\n",
      "\n",
      "Epoch [22/100], Loss: 0.0242\n",
      "\n",
      "Test set: Average loss: 9.0568\n",
      "\n",
      "Epoch [23/100], Loss: 0.0228\n",
      "\n",
      "Test set: Average loss: 8.9656\n",
      "\n",
      "Epoch [24/100], Loss: 0.0230\n",
      "\n",
      "Test set: Average loss: 8.7923\n",
      "\n",
      "Epoch [25/100], Loss: 0.0230\n",
      "\n",
      "Test set: Average loss: 8.6601\n",
      "\n",
      "Epoch [26/100], Loss: 0.0222\n",
      "\n",
      "Test set: Average loss: 8.5825\n",
      "\n",
      "Epoch [27/100], Loss: 0.0218\n",
      "\n",
      "Test set: Average loss: 8.3865\n",
      "\n",
      "Epoch [28/100], Loss: 0.0224\n",
      "\n",
      "Test set: Average loss: 8.3653\n",
      "\n",
      "Epoch [29/100], Loss: 0.0220\n",
      "\n",
      "Test set: Average loss: 8.2085\n",
      "\n",
      "Epoch [30/100], Loss: 0.0212\n",
      "\n",
      "Test set: Average loss: 8.0421\n",
      "\n",
      "Epoch [31/100], Loss: 0.0215\n",
      "\n",
      "Test set: Average loss: 7.9848\n",
      "\n",
      "Epoch [32/100], Loss: 0.0205\n",
      "\n",
      "Test set: Average loss: 7.9227\n",
      "\n",
      "Epoch [33/100], Loss: 0.0207\n",
      "\n",
      "Test set: Average loss: 7.7301\n",
      "\n",
      "Epoch [34/100], Loss: 0.0200\n",
      "\n",
      "Test set: Average loss: 7.6704\n",
      "\n",
      "Epoch [35/100], Loss: 0.0201\n",
      "\n",
      "Test set: Average loss: 7.5717\n",
      "\n",
      "Epoch [36/100], Loss: 0.0195\n",
      "\n",
      "Test set: Average loss: 7.3899\n",
      "\n",
      "Epoch [37/100], Loss: 0.0192\n",
      "\n",
      "Test set: Average loss: 7.4273\n",
      "\n",
      "Epoch [38/100], Loss: 0.0194\n",
      "\n",
      "Test set: Average loss: 7.2695\n",
      "\n",
      "Epoch [39/100], Loss: 0.0191\n",
      "\n",
      "Test set: Average loss: 7.1507\n",
      "\n",
      "Epoch [40/100], Loss: 0.0185\n",
      "\n",
      "Test set: Average loss: 7.0852\n",
      "\n",
      "Epoch [41/100], Loss: 0.0186\n",
      "\n",
      "Test set: Average loss: 7.0678\n",
      "\n",
      "Epoch [42/100], Loss: 0.0184\n",
      "\n",
      "Test set: Average loss: 6.9504\n",
      "\n",
      "Epoch [43/100], Loss: 0.0181\n",
      "\n",
      "Test set: Average loss: 6.8595\n",
      "\n",
      "Epoch [44/100], Loss: 0.0180\n",
      "\n",
      "Test set: Average loss: 6.7852\n",
      "\n",
      "Epoch [45/100], Loss: 0.0177\n",
      "\n",
      "Test set: Average loss: 6.7120\n",
      "\n",
      "Epoch [46/100], Loss: 0.0173\n",
      "\n",
      "Test set: Average loss: 6.6692\n",
      "\n",
      "Epoch [47/100], Loss: 0.0167\n",
      "\n",
      "Test set: Average loss: 6.6142\n",
      "\n",
      "Epoch [48/100], Loss: 0.0174\n",
      "\n",
      "Test set: Average loss: 6.5644\n",
      "\n",
      "Epoch [49/100], Loss: 0.0174\n",
      "\n",
      "Test set: Average loss: 6.5339\n",
      "\n",
      "Epoch [50/100], Loss: 0.0173\n",
      "\n",
      "Test set: Average loss: 6.4342\n",
      "\n",
      "Epoch [51/100], Loss: 0.0165\n",
      "\n",
      "Test set: Average loss: 6.3937\n",
      "\n",
      "Epoch [52/100], Loss: 0.0165\n",
      "\n",
      "Test set: Average loss: 6.3432\n",
      "\n",
      "Epoch [53/100], Loss: 0.0173\n",
      "\n",
      "Test set: Average loss: 6.2804\n",
      "\n",
      "Epoch [54/100], Loss: 0.0167\n",
      "\n",
      "Test set: Average loss: 6.2503\n",
      "\n",
      "Epoch [55/100], Loss: 0.0167\n",
      "\n",
      "Test set: Average loss: 6.2037\n",
      "\n",
      "Epoch [56/100], Loss: 0.0161\n",
      "\n",
      "Test set: Average loss: 6.1689\n",
      "\n",
      "Epoch [57/100], Loss: 0.0162\n",
      "\n",
      "Test set: Average loss: 6.1386\n",
      "\n",
      "Epoch [58/100], Loss: 0.0165\n",
      "\n",
      "Test set: Average loss: 6.0917\n",
      "\n",
      "Epoch [59/100], Loss: 0.0162\n",
      "\n",
      "Test set: Average loss: 6.0327\n",
      "\n",
      "Epoch [60/100], Loss: 0.0157\n",
      "\n",
      "Test set: Average loss: 6.0233\n",
      "\n",
      "Epoch [61/100], Loss: 0.0155\n",
      "\n",
      "Test set: Average loss: 5.9464\n",
      "\n",
      "Epoch [62/100], Loss: 0.0157\n",
      "\n",
      "Test set: Average loss: 5.9467\n",
      "\n",
      "Epoch [63/100], Loss: 0.0155\n",
      "\n",
      "Test set: Average loss: 5.9249\n",
      "\n",
      "Epoch [64/100], Loss: 0.0157\n",
      "\n",
      "Test set: Average loss: 5.8867\n",
      "\n",
      "Epoch [65/100], Loss: 0.0160\n",
      "\n",
      "Test set: Average loss: 5.8558\n",
      "\n",
      "Epoch [66/100], Loss: 0.0151\n",
      "\n",
      "Test set: Average loss: 5.8653\n",
      "\n",
      "Epoch [67/100], Loss: 0.0149\n",
      "\n",
      "Test set: Average loss: 5.8054\n",
      "\n",
      "Epoch [68/100], Loss: 0.0149\n",
      "\n",
      "Test set: Average loss: 5.7932\n",
      "\n",
      "Epoch [69/100], Loss: 0.0150\n",
      "\n",
      "Test set: Average loss: 5.7793\n",
      "\n",
      "Epoch [70/100], Loss: 0.0152\n",
      "\n",
      "Test set: Average loss: 5.7416\n",
      "\n",
      "Epoch [71/100], Loss: 0.0145\n",
      "\n",
      "Test set: Average loss: 5.7299\n",
      "\n",
      "Epoch [72/100], Loss: 0.0144\n",
      "\n",
      "Test set: Average loss: 5.6895\n",
      "\n",
      "Epoch [73/100], Loss: 0.0149\n",
      "\n",
      "Test set: Average loss: 5.6806\n",
      "\n",
      "Epoch [74/100], Loss: 0.0143\n",
      "\n",
      "Test set: Average loss: 5.6194\n",
      "\n",
      "Epoch [75/100], Loss: 0.0147\n",
      "\n",
      "Test set: Average loss: 5.6318\n",
      "\n",
      "Epoch [76/100], Loss: 0.0150\n",
      "\n",
      "Test set: Average loss: 5.6102\n",
      "\n",
      "Epoch [77/100], Loss: 0.0147\n",
      "\n",
      "Test set: Average loss: 5.6021\n",
      "\n",
      "Epoch [78/100], Loss: 0.0148\n",
      "\n",
      "Test set: Average loss: 5.5779\n",
      "\n",
      "Epoch [79/100], Loss: 0.0143\n",
      "\n",
      "Test set: Average loss: 5.5451\n",
      "\n",
      "Epoch [80/100], Loss: 0.0146\n",
      "\n",
      "Test set: Average loss: 5.5430\n",
      "\n",
      "Epoch [81/100], Loss: 0.0141\n",
      "\n",
      "Test set: Average loss: 5.5111\n",
      "\n",
      "Epoch [82/100], Loss: 0.0143\n",
      "\n",
      "Test set: Average loss: 5.5037\n",
      "\n",
      "Epoch [83/100], Loss: 0.0147\n",
      "\n",
      "Test set: Average loss: 5.5120\n",
      "\n",
      "Epoch [84/100], Loss: 0.0146\n",
      "\n",
      "Test set: Average loss: 5.5048\n",
      "\n",
      "Epoch [85/100], Loss: 0.0143\n",
      "\n",
      "Test set: Average loss: 5.4855\n",
      "\n",
      "Epoch [86/100], Loss: 0.0141\n",
      "\n",
      "Test set: Average loss: 5.4498\n",
      "\n",
      "Epoch [87/100], Loss: 0.0141\n",
      "\n",
      "Test set: Average loss: 5.4495\n",
      "\n",
      "Epoch [88/100], Loss: 0.0143\n",
      "\n",
      "Test set: Average loss: 5.4565\n",
      "\n",
      "Epoch [89/100], Loss: 0.0141\n",
      "\n",
      "Test set: Average loss: 5.4289\n",
      "\n",
      "Epoch [90/100], Loss: 0.0141\n",
      "\n",
      "Test set: Average loss: 5.4235\n",
      "\n",
      "Epoch [91/100], Loss: 0.0139\n",
      "\n",
      "Test set: Average loss: 5.4064\n",
      "\n",
      "Epoch [92/100], Loss: 0.0142\n",
      "\n",
      "Test set: Average loss: 5.3902\n",
      "\n",
      "Epoch [93/100], Loss: 0.0141\n",
      "\n",
      "Test set: Average loss: 5.3842\n",
      "\n",
      "Epoch [94/100], Loss: 0.0141\n",
      "\n",
      "Test set: Average loss: 5.3932\n",
      "\n",
      "Epoch [95/100], Loss: 0.0136\n",
      "\n",
      "Test set: Average loss: 5.3691\n",
      "\n",
      "Epoch [96/100], Loss: 0.0140\n",
      "\n",
      "Test set: Average loss: 5.3598\n",
      "\n",
      "Epoch [97/100], Loss: 0.0140\n",
      "\n",
      "Test set: Average loss: 5.3595\n",
      "\n",
      "Epoch [98/100], Loss: 0.0136\n",
      "\n",
      "Test set: Average loss: 5.3479\n",
      "\n",
      "Epoch [99/100], Loss: 0.0138\n",
      "\n",
      "Test set: Average loss: 5.3531\n",
      "\n",
      "Epoch [100/100], Loss: 0.0138\n",
      "\n",
      "Test set: Average loss: 5.3487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "test_accuracy_list = []\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    model.train()\n",
    "    for i, (ecog, mel) in enumerate(train_loader):\n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "#         outputs = model(images).double()\n",
    "#         labels = labels.long()\n",
    "        outputs = model(ecog)\n",
    "        labels = mel\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i) % 100 == 0:\n",
    "            train_loss_list.append(loss.item())\n",
    "            print ('Epoch [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, NUM_EPOCH, loss.item()))\n",
    "#             model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "#             with torch.no_grad():\n",
    "#                 correct = 0\n",
    "#                 total = 0\n",
    "#                 for images, labels in test_loader:\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "#                     outputs = model(images)\n",
    "#                     _, predicted = torch.max(outputs.data, 1)\n",
    "#                     total += labels.size(0)\n",
    "#                     correct += (predicted == labels).sum().item()\n",
    "\n",
    "#                 print('Test Accuracy of the model on the 250 test images: {} %'.format(100 * correct / total))\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "#         data, target = Variable(data, volatile=True), Variable(target)\n",
    "#         data = data.to(device)\n",
    "#         target = target.to(device)\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        target = target\n",
    "        test_loss += F.l1_loss(output, target, size_average=False).data\n",
    "        # get the index of the max log-probability\n",
    "#         pred = output.data.max(1, keepdim=True)[1]\n",
    "#         correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_loss_list.append(test_loss.item())\n",
    "#     test_accuracy_list.append((100. * correct / len(test_loader.dataset)).item())\n",
    "    print('\\nTest set: Average loss: {:.4f}\\n'.format(\n",
    "        test_loss))\n",
    "#             print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "#                    .format(epoch+1, NUM_EPOCH, i+1, total_step, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dataset[1][1]\n",
    "img_arr = np.asarray([t.numpy() for t in img])\n",
    "img = Variable(torch.from_numpy(img_arr[0])).view(1,1,96,125)\n",
    "img = Variable(img).view(1,96,125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_out = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_out_np = mel_out.numpy()\n",
    "mel_out_np = mel_out_np.reshape(128,3)\n",
    "# np.save('data/mel_out_np.npy', mel_out_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(mel_out_np, interpolation='nearest')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
